{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_3xxr5fb",
    "id": "B116BFDF0D464FF49A85A582357D0B4D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 线性回归\n",
    "主要内容包括：\n",
    "\n",
    "1. 线性回归的基本要素\n",
    "2. 线性回归模型从零开始的实现\n",
    "3. 线性回归模型使用pytorch的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ht8ukap",
    "id": "8FCA1BC77B7F479BA1398473C2691BB0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 线性回归的基本要素\n",
    "\n",
    "### 模型\n",
    "为了简单起见，这里我们假设价格只取决于房屋状况的两个因素，即面积（平方米）和房龄（年）。接下来我们希望探索价格与这两个因素的具体关系。线性回归假设输出与各个输入之间是线性关系:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 数据集\n",
    "我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。\n",
    "### 损失函数\n",
    "在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为 $i$ 的样本误差的表达式为\n",
    "\n",
    "\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.\n",
    "$$\n",
    "\n",
    "\n",
    "### 优化函数 - 随机梯度下降\n",
    "当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。\n",
    "\n",
    "在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。   \n",
    "\n",
    "$$\n",
    "(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n",
    "$$\n",
    "  \n",
    "学习率: $\\eta$代表在每次优化中，能够学习的步长的大小    \n",
    "批量大小: $\\mathcal{B}$是小批量计算中的批量大小batch size   \n",
    "\n",
    "总结一下，优化函数的有以下两个步骤：\n",
    "\n",
    "- (i)初始化模型参数，一般来说使用随机初始化；\n",
    "- (ii)我们在数据上迭代多次，通过在负梯度方向移动参数来更新每个参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_v3gyr0b",
    "id": "469D697FF90B48B7B0B61AED429EB8D6",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 矢量计算\n",
    "在模型训练或预测时，我们常常会同时处理多个数据样本并用到矢量计算。在介绍线性回归的矢量计算表达式之前，让我们先考虑对两个向量相加的两种方法。\n",
    "\n",
    "\n",
    "1. 向量相加的一种方法是，将这两个向量按元素逐一做标量加法。\n",
    "2. 向量相加的另一种方法是，将这两个向量直接做矢量加法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# init variable a, b as 1000 dimension vector\n",
    "n = 1000\n",
    "a = torch.ones(n)\n",
    "b = torch.ones(n)\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a timer class to record time\n",
    "class Timer(object):\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        # start the timer\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        # stop the timer and record time into a list\n",
    "        self.times.append(time.time() - self.start_time)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        # calculate the average and return\n",
    "        return sum(self.times)/len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        # return the sum of recorded time\n",
    "        return sum(self.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_g9h7dg8",
    "id": "2698821CF46844989522D09B8B1C76DB",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "现在我们可以来测试了。首先将两个向量使用for循环按元素逐一做标量加法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-197773d5d165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m'%.5f sec'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8e6176461da9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8e6176461da9>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# start the timer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "timer = Timer()\n",
    "c = torch.zeros(n)\n",
    "for i in range(n):\n",
    "    c[i] = a[i] + b[i]\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_akkwkh8",
    "id": "B00F06B72BB5471DA82C945B04FED140",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "另外是使用torch来将两个向量直接做矢量加法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "graffitiCellId": "id_a8sw68j",
    "id": "6D2503874A514A7590AF8F710B5F325C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00054 sec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "d = a + b\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_oonn3xx",
    "id": "B0CA3D998E0A4B5C848F9C1BAC37DB13",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "结果很明显,后者比前者运算速度更快。因此，我们应该尽可能采用矢量计算，以提升计算效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_3y8h3t7",
    "id": "84D91561397548D7ACB5FAB71E66AB9B",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 线性回归模型从零开始的实现\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "graffitiCellId": "id_3snj2zc",
    "id": "B3148881D9514B898929430997FD781C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "# import packages and modules\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ofruiuq",
    "id": "D7C96AC35B12411E8A1530B965CB34E0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 生成数据集\n",
    "使用线性模型来生成数据集，生成一个1000个样本的数据集，下面是用来生成数据的线性关系：\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "graffitiCellId": "id_h3bosrm",
    "id": "1A5F9ED7F99643A3A440960077439F0F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set input feature number \n",
    "num_inputs = 2\n",
    "# set example number\n",
    "num_examples = 1000\n",
    "\n",
    "# set true weight and bias in order to generate corresponded label\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.randn(num_examples, num_inputs,\n",
    "                      dtype=torch.float32)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()),\n",
    "                       dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_gr10soh",
    "id": "937B9B59AC2343B58488AAA9B7C11C2A",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 使用图像来展示生成的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "graffitiCellId": "id_ov2af2a",
    "id": "8E2E1E16060241C6A33E4CF1EC65DF1D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_iivzo2j",
    "id": "27981A0FD4054AC39194415A90F313EC",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "graffitiCellId": "id_0tj7eus",
    "id": "A6E1419DA00C4ABF8CBF0E0F0B2B9E35",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)  # random read 10 samples\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # the last time may be not enough for a whole batch\n",
    "        yield  features.index_select(0, j), labels.index_select(0, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "graffitiCellId": "id_xc0arq3",
    "id": "1DA3BC30E43E4F76970F712D89BDBC4D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1565, -1.1233],\n",
      "        [-0.8087, -0.2324],\n",
      "        [ 0.8397,  0.4556],\n",
      "        [ 0.6066,  0.4042],\n",
      "        [ 0.5413, -2.5798],\n",
      "        [-0.2162, -0.9397],\n",
      "        [-0.3928,  0.5014],\n",
      "        [-0.2184,  1.3679],\n",
      "        [ 1.7103,  0.8592],\n",
      "        [-0.9732, -1.7086]]) \n",
      " tensor([ 8.3447,  3.3746,  4.3218,  4.0390, 14.0457,  6.9441,  1.7080, -0.8941,\n",
      "         4.6901,  8.0539])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_hj6sxxx",
    "id": "1FF819B45B1F44C88012EBB266C10EE8",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "graffitiCellId": "id_g06bzki",
    "id": "6B11AC0E574140CD9C2E722B05D0049D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32)\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "\n",
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_zvsctyc",
    "id": "A91414B8FDF24835A06B6ADFAEC2C15C",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 定义模型\n",
    "定义用来训练参数的训练模型：\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "graffitiCellId": "id_l8xu5kf",
    "id": "8DFF5BDD78884936899E3CE720BEEE3C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    return torch.mm(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_1sta0nq",
    "id": "C9B747281D1842C682F2AEB1F38B959D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 定义损失函数\n",
    "我们使用的是均方误差损失函数：\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "graffitiCellId": "id_r9p6ncn",
    "id": "58A55DD7B46842578BEA1A8689456B1A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y): \n",
    "    return (y_hat - y.view(y_hat.size())) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_jm7ie9i",
    "id": "0A98B83A8FFD4E84B6EFE8A894643634",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 定义优化函数\n",
    "在这里优化函数使用的是小批量随机梯度下降：\n",
    "\n",
    "$$\n",
    "(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n",
    "$$\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "graffitiCellId": "id_e41t41x",
    "id": "E9676D1B4F80473B894A4ADA3691D2E0",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size): \n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # ues .data to operate param without gradient track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_0nsokgo",
    "id": "B18F2D19AA1140478E2E327ECC97F40F",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 训练\n",
    "当数据集、模型、损失函数和优化函数定义完了之后就可来准备进行模型的训练了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "graffitiCellId": "id_ht68g0d",
    "id": "8C7AA862EE5A4AEAB3CB980F15870D06",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000050\n",
      "epoch 2, loss 0.000049\n",
      "epoch 3, loss 0.000049\n",
      "epoch 4, loss 0.000049\n",
      "epoch 5, loss 0.000049\n",
      "epoch 6, loss 0.000049\n",
      "epoch 7, loss 0.000049\n",
      "epoch 8, loss 0.000049\n",
      "epoch 9, loss 0.000050\n",
      "epoch 10, loss 0.000049\n"
     ]
    }
   ],
   "source": [
    "# super parameters init\n",
    "lr = 0.03\n",
    "num_epochs = 10\n",
    "\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "# training\n",
    "for epoch in range(num_epochs):  # training repeats num_epochs times\n",
    "    # in each epoch, all the samples in dataset will be used once\n",
    "    \n",
    "    # X is the feature and y is the label of a batch sample\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y).sum()  \n",
    "        # calculate the gradient of batch sample loss \n",
    "        l.backward()  \n",
    "        # using small batch random gradient descent to iter model parameters\n",
    "        sgd([w, b], lr, batch_size)  \n",
    "        # reset parameter gradient\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "graffitiCellId": "id_6t702dg",
    "id": "2E791A3F92EF4CCF91E2096630C0E8D9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.0005],\n",
       "         [-3.4000]], requires_grad=True),\n",
       " [2, -3.4],\n",
       " tensor([4.1998], requires_grad=True),\n",
       " 4.2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, true_w, b, true_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_pi6pxp6",
    "id": "7E8D79B69557446883330AB1E8DE07E2",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 线性回归模型使用pytorch的简洁实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "graffitiCellId": "id_sdic11w",
    "id": "D5CCF3AE67794558930978F1815C38B9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "torch.manual_seed(1)\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_07nlorv",
    "id": "34B9AE6FB3D64DFD83E93D5CEF9EEE65",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 生成数据集\n",
    "在这里生成数据集跟从零开始的实现中是完全一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "graffitiCellId": "id_k7z5rd0",
    "id": "83C2DB9468394624BB4934DBF194A353",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_io6yz0p",
    "id": "0FB74CD3CD784A82B2A422E54BB0DEDD",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "graffitiCellId": "id_bxmqh9f",
    "id": "8704CA375BF04440839AB16AA995E3AB",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# combine featues and labels of dataset\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "\n",
    "# put dataset into DataLoader\n",
    "data_iter = Data.DataLoader(\n",
    "    dataset=dataset,            # torch TensorDataset format\n",
    "    batch_size=batch_size,      # mini batch size\n",
    "    shuffle=True,               # whether shuffle the data or not\n",
    "    num_workers=2,              # read data in multithreading\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "graffitiCellId": "id_nnjw15x",
    "id": "C1FFC0FD8F5741D78AFD26B883BE192C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_zobpfwu",
    "id": "F9085AAAB3BB45E289329A5EA5446848",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "graffitiCellId": "id_gxy6vho",
    "id": "28DD8C6981314D148B5FD1915639151C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(LinearNet, self).__init__()      # call father function to init \n",
    "        self.linear = nn.Linear(n_feature, 1)  # function prototype: `torch.nn.Linear(in_features, out_features, bias=True)`\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "    \n",
    "net = LinearNet(num_inputs)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "graffitiCellId": "id_q5pjt1j",
    "id": "56CADFC7B65448BC989411C2C9950816",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# ways to init a multilayer network\n",
    "# method one\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(num_inputs, 1)\n",
    "    # other layers can be added here\n",
    "    )\n",
    "\n",
    "# method two\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear', nn.Linear(num_inputs, 1))\n",
    "# net.add_module ......\n",
    "\n",
    "# method three\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(OrderedDict([\n",
    "          ('linear', nn.Linear(num_inputs, 1))\n",
    "          # ......\n",
    "        ]))\n",
    "\n",
    "print(net)\n",
    "print(net[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_fl434p3",
    "id": "1BE602743BCD4C5D948A24212760162D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "graffitiCellId": "id_zdl7vmt",
    "id": "025B064D1ED1432385DEE75240A790F6",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net[0].weight, mean=0.0, std=0.01)\n",
    "init.constant_(net[0].bias, val=0.0)  # or you can use `net[0].bias.data.fill_(0)` to modify it directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "graffitiCellId": "id_7s9m78k",
    "id": "C6A909A717B545E6802264EBD711588D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0152,  0.0038]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_l729glu",
    "id": "BBFF587F757A4C7EB49AD0D536AD363E",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "graffitiCellId": "id_or1wah4",
    "id": "B721F8DD4811434BB1984B5B2DABC143",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()    # nn built-in squared loss function\n",
    "                       # function prototype: `torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_zyt512e",
    "id": "6490FA20F3D4462CB2B98902F694E525",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "graffitiCellId": "id_pmx4gbq",
    "id": "1998CEB53B534F178AC6223011627B0B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)   # built-in random gradient descent function\n",
    "print(optimizer)  # function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_n2klgfl",
    "id": "090AC5BD4E214B75BD7C4AB9B68720D0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "graffitiCellId": "id_qj2fl3l",
    "id": "A4B0F83F71F94728811A619F1AE74CD2",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.000054\n",
      "epoch 2, loss: 0.000099\n",
      "epoch 3, loss: 0.000117\n",
      "epoch 4, loss: 0.000065\n",
      "epoch 5, loss: 0.000163\n",
      "epoch 6, loss: 0.000074\n",
      "epoch 7, loss: 0.000099\n",
      "epoch 8, loss: 0.000114\n",
      "epoch 9, loss: 0.000043\n",
      "epoch 10, loss: 0.000072\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        output = net(X)\n",
    "        l = loss(output, y.view(-1, 1))\n",
    "        optimizer.zero_grad() # reset gradient, equal to net.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "graffitiCellId": "id_ke4hsr4",
    "id": "704087439A114181B3A7FE79539127AB",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result comparision\n",
    "dense = net[0]\n",
    "print(true_w, dense.weight.data)\n",
    "print(true_b, dense.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_v7cg0i4",
    "id": "A968DC29635C4CDF8394A6F779661DC5",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 两种实现方式的比较\n",
    "1. 从零开始的实现（推荐用来学习）\n",
    "\n",
    "   能够更好的理解模型和神经网络底层的原理\n",
    "   \n",
    "\n",
    "2. 使用pytorch的简洁实现\n",
    "\n",
    "   能够更加快速地完成模型的设计与实现\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}